{"cells":[{"cell_type":"code","execution_count":null,"id":"8a2d2c97","metadata":{"id":"8a2d2c97"},"outputs":[],"source":["#######################################################\n","#######################################################\n","############    COPYRIGHT - DATA SOCIETY   ############\n","#######################################################\n","#######################################################\n","\n","## 2 LOGISTICREGRESSION/LOGISTICREGRESSION/LOGISTICREGRESSION LOGISTICREGRESSION 2 ##\n","\n","## NOTE: To run individual pieces of code, select the line of code and\n","##       press ctrl + enter for PCs or command + enter for Macs\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4288179f","metadata":{"id":"4288179f"},"outputs":[],"source":["#=================================================-\n","#### Slide 3: Loading packages  ####\n","\n","import os\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","# Helper packages.\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","# Scikit-learn package for logistic regression.\n","from sklearn import linear_model\n","# Model set up and tuning packages from scikit-learn.\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","# Scikit-learn packages for evaluating model performance.\n","from sklearn import metrics\n","# Scikit-learn package for data preprocessing.\n","from sklearn import preprocessing\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"19f9f038","metadata":{"id":"19f9f038"},"outputs":[],"source":["#=================================================-\n","#### Slide 4: Directory settings  ####\n","\n","# Set 'main_dir' to location of the project folder\n","home_dir = Path(\".\").resolve()\n","main_dir = home_dir.parent.parent\n","print(main_dir)\n","data_dir = str(main_dir) + \"/data\"\n","print(data_dir)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"a1c4ffff","metadata":{"id":"a1c4ffff"},"outputs":[],"source":["#=================================================-\n","#### Slide 8: Loading data into Python  ####\n","\n","df = pd.read_csv(str(data_dir)+\"/\"+ 'healthcare-dataset-stroke-data.csv')\n","print(df.head())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"fdd3f8dd","metadata":{"id":"fdd3f8dd"},"outputs":[],"source":["#=================================================-\n","#### Slide 9: Subset data  ####\n","\n","df_subset = df[['age', 'avg_glucose_level', 'heart_disease', 'ever_married', 'hypertension', 'Residence_type', 'gender', 'smoking_status', 'work_type', 'stroke', 'id']]\n","print(df_subset.head())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"be196f1c","metadata":{"id":"be196f1c"},"outputs":[],"source":["#=================================================-\n","#### Slide 10: Convert target to binary  ####\n","\n","# Target is binary\n","print(df_subset['stroke'].head())\n","# Identify the the two unique classes\n","unique_values = sorted(df_subset['stroke'].unique())\n","df_subset['stroke'] = np.where(df_subset['stroke'] == unique_values[0],  False,True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"64cdf412","metadata":{"id":"64cdf412"},"outputs":[],"source":["#=================================================-\n","#### Slide 13: Data prep: target variable  ####\n","\n","print(df_subset['stroke'].dtypes)\n","# Identify the the two unique classes\n","unique_values = sorted(df_subset['stroke'].unique())\n","df_subset['stroke'] = np.where(df_subset['stroke'] == unique_values[0],  False,True)\n","# Check class again.\n","print(df_subset['stroke'].dtypes)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"93e1f644","metadata":{"id":"93e1f644"},"outputs":[],"source":["#=================================================-\n","#### Slide 14: Data prep: check for NAs  ####\n","\n"," # Check for NAs.\n","print(df_subset.isnull().sum())\n","percent_missing = df_subset.isnull().sum() * 100 / len(df_subset)\n","print(percent_missing)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e6133e13","metadata":{"id":"e6133e13"},"outputs":[],"source":["#=================================================-\n","#### Slide 15: Data prep: check for NAs (cont'd)  ####\n","\n","# Delete columns containing either 50% or more than 50% NaN Values\n","perc = 50.0\n","min_count =  int(((100-perc)/100)*df_subset.shape[0] + 1)\n","df_subset = df_subset.dropna(axis=1,\n","               thresh=min_count)\n","print(df_subset.shape)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"939ca3bf","metadata":{"id":"939ca3bf"},"outputs":[],"source":["#=================================================-\n","#### Slide 16: Data prep: check for NAs (cont'd)  ####\n","\n","# Function to impute NA in both numeric and categorical columns\n","def fillna(df):\n","    # Fill numeric columns with mean value\n","    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n","    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n","\n","    # Fill categorical columns with mode value\n","    categorical_cols = df.select_dtypes(include=['object']).columns\n","    df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n","\n","    return df\n","\n","df_subset = fillna(df_subset)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"34ad8ed7","metadata":{"id":"34ad8ed7"},"outputs":[],"source":["#=================================================-\n","#### Slide 17: Data prep: split data   ####\n","\n","# Split the data into X and y\n","columns_to_drop_from_X = ['stroke'] + ['id']\n","X = df_subset.drop(columns_to_drop_from_X, axis = 1)\n","y = np.array(df_subset['stroke'])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c8c1dff8","metadata":{"id":"c8c1dff8"},"outputs":[],"source":["#=================================================-\n","#### Slide 21: Data prep: convert categorical data columns to dummies  ####\n","\n","print(X.dtypes)\n","X = pd.get_dummies(X, columns = ['heart_disease', 'ever_married', 'hypertension', 'Residence_type', 'gender', 'smoking_status', 'work_type'], dtype=float, drop_first=True)\n","print(X.dtypes)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"f34a8d8d","metadata":{"id":"f34a8d8d"},"outputs":[],"source":["#=================================================-\n","#### Slide 22: Split into train and test set  ####\n","\n","# Set the seed.\n","np.random.seed(1)\n","\n","# Split data into train and test sets, use a 70 train - 30 test split.\n","X_train, X_test, y_train, y_test = train_test_split(X,\n","                                                    y,\n","                                                    test_size = .3)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b1d9a596","metadata":{"id":"b1d9a596"},"outputs":[],"source":["#=================================================-\n","#### Slide 25: Scale the features (cont'd)  ####\n","\n","# Initialize scaler.\n","scaler = preprocessing.MinMaxScaler()\n","\n","# Fit on training data.\n","scaler.fit(X_train)\n","\n","# Scale training and test data.\n","X_train_scaled = scaler.transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e33e8590","metadata":{"id":"e33e8590"},"outputs":[],"source":["#=================================================-\n","#### Slide 29: Logistic regression: build  ####\n","\n","# Set up logistic regression model.\n","logistic_regression_model = linear_model.LogisticRegression()\n","print(logistic_regression_model)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3710a171","metadata":{"id":"3710a171"},"outputs":[],"source":["#=================================================-\n","#### Slide 31: Logistic regression: fit (cont'd)  ####\n","\n","# Fit the model.\n","logistic_regression_model.fit(X_train_scaled,\n","                              y_train)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6d757067","metadata":{"id":"6d757067"},"outputs":[],"source":["#=================================================-\n","#### Slide 32: Logistic regression: predict  ####\n","\n","# Predict on test data.\n","predicted_values = logistic_regression_model.predict(X_test_scaled)\n","print(predicted_values[:20])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"7e27f745","metadata":{"id":"7e27f745"},"outputs":[],"source":["#=================================================-\n","#### Slide 39: Confusion matrix and accuracy  ####\n","\n","# Take a look at test data confusion matrix.\n","conf_matrix_test = metrics.confusion_matrix(y_test, predicted_values)\n","print(conf_matrix_test)\n","# Compute test model accuracy score.\n","test_accuracy_score = metrics.accuracy_score(y_test, predicted_values)\n","print(\"Accuracy on test data: \", test_accuracy_score)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4adce2c3","metadata":{"id":"4adce2c3"},"outputs":[],"source":["#=================================================-\n","#### Slide 40: Classification report  ####\n","\n","# Create a list of target names to interpret class assignments.\n","target_names = df_subset['stroke'].unique()\n","target_names=target_names.tolist()\n","target_names = [str(x) for x in target_names]\n","# Print an entire classification report.\n","class_report = metrics.classification_report(y_test,\n","                                             predicted_values,\n","                                             target_names = target_names)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"515768c6","metadata":{"id":"515768c6"},"outputs":[],"source":["#=================================================-\n","#### Slide 41: Classification report (cont'd)  ####\n","\n","print(class_report)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"edd323f8","metadata":{"id":"edd323f8"},"outputs":[],"source":["#=================================================-\n","#### Slide 45: Save accuracy score  ####\n","\n","model_final = {'metrics' : \"accuracy\" ,\n","                'values' : round(test_accuracy_score,4),\n","                'model':'logistic' }\n","print(model_final)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4951075b","metadata":{"id":"4951075b"},"outputs":[],"source":["#=================================================-\n","#### Slide 46: Getting probabilities instead of class labels  ####\n","\n","# Get probabilities instead of predicted values.\n","test_probabilities = logistic_regression_model.predict_proba(X_test_scaled)\n","print(test_probabilities[0:5, :])\n","# Get probabilities of test predictions only.\n","test_predictions = test_probabilities[:, 1]\n","print(test_predictions[0:5])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6b43c1dc","metadata":{"id":"6b43c1dc"},"outputs":[],"source":["#=================================================-\n","#### Slide 47: Computing FPR, TPR, and threshold  ####\n","\n","# Get FPR, TPR, and threshold values.\n","fpr, tpr, threshold = metrics.roc_curve(y_test,            #<- test data labels\n","                                        test_predictions)  #<- predicted probabilities\n","print(\"False positive: \", fpr[:5])\n","print(\"True positive: \", tpr[:5])\n","print(\"Threshold: \", threshold[:5])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8a8ea362","metadata":{"id":"8a8ea362"},"outputs":[],"source":["#=================================================-\n","#### Slide 48: Computing AUC  ####\n","\n","# Get AUC by providing the FPR and TPR.\n","auc = metrics.auc(fpr, tpr)\n","print(\"Area under the ROC curve: \", auc)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d20b40e5","metadata":{"id":"d20b40e5"},"outputs":[],"source":["#=================================================-\n","#### Slide 49: Putting it all together: ROC plot  ####\n","\n","# Make an ROC curve plot.\n","plt.title('Receiver Operator Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.show()\n","\n","\n","#######################################################\n","####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n","#######################################################\n"]},{"cell_type":"code","execution_count":null,"id":"6b196beb","metadata":{"id":"6b196beb"},"outputs":[],"source":["#######################################################\n","#######################################################\n","############    COPYRIGHT - DATA SOCIETY   ############\n","#######################################################\n","#######################################################\n","\n","## 2 LOGISTICREGRESSION/LOGISTICREGRESSION/LOGISTICREGRESSION LOGISTICREGRESSION 3 ##\n","\n","## NOTE: To run individual pieces of code, select the line of code and\n","##       press ctrl + enter for PCs or command + enter for Macs\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0b52f418","metadata":{"id":"0b52f418"},"outputs":[],"source":["#=================================================-\n","#### Slide 3: Accuracy on train vs. accuracy on test  ####\n","\n","# Compute trained model accuracy score.\n","trained_accuracy_score = logistic_regression_model.score(X_train_scaled, y_train)\n","print(\"Accuracy on train data: \" , trained_accuracy_score)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ec3383bb","metadata":{"id":"ec3383bb"},"outputs":[],"source":["#=================================================-\n","#### Slide 15: Prepare parameters for optimization  ####\n","\n","# Create regularization penalty space.\n","penalty = ['l1', 'l2']\n","# Create regularization constant space.\n","C = np.logspace(0, 10, 10)\n","print(\"Regularization constant: \", C)\n","# Create hyperparameter options dictionary.\n","hyperparameters = dict(C = C, penalty = penalty)\n","print(hyperparameters)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"f0844074","metadata":{"id":"f0844074"},"outputs":[],"source":["#=================================================-\n","#### Slide 16: Set up cross-validation logistic function  ####\n","\n","# Grid search 10-fold cross-validation with above parameters.\n","clf = GridSearchCV(linear_model.LogisticRegression(solver='liblinear'), #<- function to optimize\n","                   hyperparameters,                   #<- grid search parameters\n","                   cv = 10,                           #<- 10-fold cv\n","                   verbose = 0)                       #<- no messages to show\n","# Fit CV grid search.\n","best_model = clf.fit(X_train_scaled, y_train)\n","best_model\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e32d52c7","metadata":{"id":"e32d52c7"},"outputs":[],"source":["#=================================================-\n","#### Slide 17: Check best parameters found by CV  ####\n","\n","# Get best penalty and constant parameters.\n","penalty = best_model.best_estimator_.get_params()['penalty']\n","constant = best_model.best_estimator_.get_params()['C']\n","print('Best penalty: ', penalty)\n","print('Best C: ', constant)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"100c41ae","metadata":{"id":"100c41ae"},"outputs":[],"source":["#=================================================-\n","#### Slide 18: Predict using the best model parameters  ####\n","\n","# Predict on test data using best model.\n","best_predicted_values = best_model.predict(X_test_scaled)\n","print(best_predicted_values)\n","# Compute best model accuracy score.\n","best_accuracy_score = metrics.accuracy_score(y_test, best_predicted_values)\n","print(\"Accuracy on test data (best model): \", best_accuracy_score)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b51f8a84","metadata":{"id":"b51f8a84"},"outputs":[],"source":["#=================================================-\n","#### Slide 19: Accuracy on train vs. accuracy on test  ####\n","\n","# Compute trained model accuracy score.\n","trained_accuracy_score = best_model.score(X_train_scaled, y_train)\n","print(\"Accuracy on train data: \" , trained_accuracy_score)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"bec8222c","metadata":{"id":"bec8222c"},"outputs":[],"source":["#=================================================-\n","#### Slide 20: Assessing the tuned model  ####\n","\n","# Compute confusion matrix for best model.\n","best_confusion_matrix = metrics.confusion_matrix(y_test, best_predicted_values)\n","print(best_confusion_matrix)\n","# Create a list of target names to interpret class assignments.\n","target_names = ['Low value', 'High value']\n","# Compute classification report for best model.\n","best_class_report = metrics.classification_report(y_test, best_predicted_values,\n","                                                  target_names = target_names)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"53d3f0fd","metadata":{"id":"53d3f0fd"},"outputs":[],"source":["#=================================================-\n","#### Slide 21: Assessing the tuned model (cont'd)  ####\n","\n","print(best_class_report)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4c023c25","metadata":{"id":"4c023c25"},"outputs":[],"source":["#=================================================-\n","#### Slide 22: Save accuracy score  ####\n","\n","model_final = {'metrics' : \"accuracy\",\n","                                  'values' : round(best_accuracy_score, 4),\n","                                  'model':'logistic_tuned' }\n","print(model_final)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"93edd979","metadata":{"id":"93edd979"},"outputs":[],"source":["#=================================================-\n","#### Slide 23: Get metrics for ROC curve  ####\n","\n","# Get probabilities instead of predicted values.\n","best_test_probabilities = best_model.predict_proba(X_test_scaled)\n","print(best_test_probabilities[0:5, ])\n","# Get probabilities of test predictions only.\n","best_test_predictions = best_test_probabilities[:, 1]\n","print(best_test_predictions[0:5])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"731cc6f4","metadata":{"id":"731cc6f4"},"outputs":[],"source":["#=================================================-\n","#### Slide 24: Get metrics for ROC curve (cont'd)  ####\n","\n","# Get ROC curve metrics.\n","best_fpr, best_tpr, best_threshold = metrics.roc_curve(y_test, best_test_predictions)\n","best_auc = metrics.auc(best_fpr, best_tpr)\n","print(best_auc)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3e1c66ad","metadata":{"id":"3e1c66ad"},"outputs":[],"source":["#=================================================-\n","#### Slide 25: Plot ROC curve for both models  ####\n","\n","# Make an ROC curve plot.\n","plt.title('Receiver Operator Characteristic')\n","plt.plot(fpr, tpr, 'blue', label = 'AUC = %0.2f' % auc)\n","plt.plot(best_fpr, best_tpr, 'black', label = 'AUC (optimized) = %0.2f' % best_auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4040beb2","metadata":{"id":"4040beb2"},"outputs":[],"source":["#=================================================-\n","#### Slide 27: Exercise  ####\n","\n","\n","\n","\n","#######################################################\n","####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n","#######################################################\n"]}],"metadata":{"language":"python","colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}